{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import importlib.util\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "parse_times = [\"MKOPEN\", \"MKCLOSE\", \"MKEMHOPEN\", \"MKEMHCLOSE\",\n",
    "               \"MKOPENYEST\", \"MKCLOSEYEST\", \"MKOPENTOM\",\n",
    "               \"MKCLOSETOM\",\"EPOPEN\", \"EPCLOSE\", \"EPEMHOPEN\",\n",
    "               \"EPEMHCLOSE\", \"EPOPENYEST\", \"EPCLOSEYEST\",\n",
    "               \"EPOPENTOM\", \"EPCLOSETOM\", \"HSOPEN\", \"HSCLOSE\",\n",
    "               \"HSEMHOPEN\", \"HSEMHCLOSE\", \"HSOPENYEST\", \"HSCLOSEYEST\",\n",
    "               \"HSOPENTOM\", \"HSCLOSETOM\", \"AKOPEN\", \"AKCLOSE\",\n",
    "               \"AKEMHOPEN\", \"AKOPENYEST\", \"AKCLOSEYEST\",\"AKEMHCLOSE\",\n",
    "               \"AKOPENTOM\", \"AKCLOSETOM\", \"MKPRDDT1\", \"MKPRDDT2\",\n",
    "               \"MKPRDNT1\", \"MKPRDNT2\", \"MKFIRET1\", \"MKFIRET2\",\n",
    "               \"EPFIRET1\", \"EPFIRET2\", \"HSPRDDT1\", \"HSFIRET1\",\n",
    "               \"HSFIRET2\", \"HSSHWNT1\", \"HSSHWNT2\", \"AKPRDDT1\",\n",
    "               \"AKPRDDT2\", \"AKSHWNT1\", \"AKSHWNT2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load posted wait time datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the module that needs to be\n",
    "# imported relative to the path of the\n",
    "# module\n",
    "spec = importlib.util.spec_from_file_location(\"loadTrainTestPostedWaitTimes\", \"../src/data/loadTrainTestData.py\")\n",
    "\n",
    "# creates a new module based on spec\n",
    "loadTrainPosted = importlib.util.module_from_spec(spec)\n",
    "\n",
    "# executes the module in its own namespace\n",
    "# when a module is imported or reloaded.\n",
    "spec.loader.exec_module(loadTrainPosted)\n",
    "\n",
    "X_train, X_test, y_train, y_test = loadTrainPosted.loadTrainTestPostedWaitTimes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert key data points from date to integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"MONTHOFYEAR\"] = X_train[\"date\"].dt.month.astype(\"Int8\")\n",
    "X_train[\"YEAR\"] = X_train[\"date\"].dt.year.astype(\"Int16\")\n",
    "X_train[\"DAYOFYEAR\"] = X_train[\"date\"].dt.dayofyear.astype(\"Int16\")\n",
    "X_train[\"HOUROFDAY\"] = X_train[\"datetime\"].dt.hour.astype(\"Int8\")\n",
    "\n",
    "X_test[\"MONTHOFYEAR\"] = X_test[\"date\"].dt.month.astype(\"Int8\")\n",
    "X_test[\"YEAR\"] = X_test[\"date\"].dt.year.astype(\"Int16\")\n",
    "X_test[\"DAYOFYEAR\"] = X_test[\"date\"].dt.dayofyear.astype(\"Int16\")\n",
    "X_test[\"HOUROFDAY\"] = X_test[\"datetime\"].dt.hour.astype(\"Int8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort by datetime before imputation (keeping y-values associated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([X_train, y_train], axis=1).sort_values(['datetime'])\n",
    "test = pd.concat([X_test, y_test], axis=1).sort_values(['datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_impute = train.drop(columns=[\"POSTED_WAIT\"])\n",
    "y_train = train[\"POSTED_WAIT\"]\n",
    "\n",
    "X_test_impute = test.drop(columns=[\"POSTED_WAIT\"])\n",
    "y_test = test[\"POSTED_WAIT\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Many open/close times, parade times, etc. are in HH:MM format. \n",
    "\n",
    "Convert to integer hour & fill nulls with 99.\n",
    "\n",
    "This means that particulate event does not exist for that day. (e.g. Magic Kingdom doesn't have a second parade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in parse_times:\n",
    "    X_train_impute[col] =  X_train_impute[col].fillna(\"99\")\n",
    "    X_train_impute[f\"{col}_HOUR\"] = X_train_impute[col].apply(lambda x: x[:2] if x[0]!=0 else x[:1]).astype(int).astype(\"Int8\")\n",
    "    X_train_impute.drop(columns = col, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in parse_times:\n",
    "    X_test_impute[col] =  X_test_impute[col].fillna(\"99\")\n",
    "    X_test_impute[f\"{col}_HOUR\"] = X_test_impute[col].apply(lambda x: x[:2] if x[0]!=0 else x[:1]).astype(int).astype(\"Int8\")\n",
    "    X_test_impute.drop(columns = col, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WDWMAXTEMP\n",
      "WDWMINTEMP\n",
      "WDWMEANTEMP\n",
      "inSession\n",
      "inSession_Enrollment\n",
      "inSession_wdw\n",
      "inSession_dlr\n",
      "inSession_sqrt_WDW\n",
      "inSession_sqrt_DLR\n",
      "inSession_California\n",
      "inSession_DC\n",
      "inSession_Central_FL\n",
      "inSession_Drive1_FL\n",
      "inSession_Drive2_FL\n",
      "inSession_Drive_CA\n",
      "inSession_Florida\n",
      "inSession_Mardi_Gras\n",
      "inSession_Midwest\n",
      "inSession_NY_NJ\n",
      "inSession_NY_NJ_PA\n",
      "inSession_New_England\n",
      "inSession_New_Jersey\n",
      "inSession_Nothwest\n",
      "INSESSION_PLANES\n",
      "inSession_SoCal\n",
      "inSession_Southwest\n"
     ]
    }
   ],
   "source": [
    "for col in X_train_impute.columns:\n",
    "    nulls = X_train_impute[col].isnull().sum()\n",
    "    \n",
    "    if nulls>0:\n",
    "        print(col)\n",
    "        X_train_impute[col].fillna(method ='bfill', inplace=True)\n",
    "    \n",
    "        if X_train_impute[col].isnull().sum()>0:\n",
    "            X_train_impute[col].fillna(X_train_impute[col].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WDWMAXTEMP\n",
      "WDWMINTEMP\n",
      "WDWMEANTEMP\n",
      "inSession\n",
      "inSession_Enrollment\n",
      "inSession_wdw\n",
      "inSession_dlr\n",
      "inSession_sqrt_WDW\n",
      "inSession_sqrt_DLR\n",
      "inSession_California\n",
      "inSession_DC\n",
      "inSession_Central_FL\n",
      "inSession_Drive1_FL\n",
      "inSession_Drive2_FL\n",
      "inSession_Drive_CA\n",
      "inSession_Florida\n",
      "inSession_Mardi_Gras\n",
      "inSession_Midwest\n",
      "inSession_NY_NJ\n",
      "inSession_NY_NJ_PA\n",
      "inSession_New_England\n",
      "inSession_New_Jersey\n",
      "inSession_Nothwest\n",
      "INSESSION_PLANES\n",
      "inSession_SoCal\n",
      "inSession_Southwest\n"
     ]
    }
   ],
   "source": [
    "for col in X_test_impute.columns:\n",
    "    nulls = X_test_impute[col].isnull().sum()\n",
    "    \n",
    "    if nulls>0:\n",
    "        print(col)\n",
    "        X_test_impute[col]= X_test_impute[col].fillna(method ='bfill')\n",
    "        \n",
    "        if X_test_impute[col].isnull().sum()>0:\n",
    "            X_test_impute[col].fillna(X_test_impute[col].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_encoded = X_train_impute.drop(columns=['date', 'datetime', 'Unnamed: 0'])\n",
    "X_test_encoded = X_test_impute.drop(columns=['date', 'datetime', 'Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train_impute, X_test_impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DROPPING BOOL:  ['HOLIDAYN_ash|val', 'HOLIDAYN_chv|pas', 'HOLIDAYN_cmd|han', 'HOLIDAYN_col|suk', 'HOLIDAYN_hal|nvd', 'HOLIDAYN_njc|vet', 'MKeventN_dah|emm', 'HSeventN_wdwsotf', \"HSFIREN_disney's hollywood studios special july 4th fireworks presentation\", \"HSFIREN_new year's eve fireworks\", 'Wind Speed Quality_a', 'Wind Speed Quality_p', 'Wind Speed Quality_passed gross limits check if element is present', 'Cloud Quality Code_erroneous, data originate from an ncei data source', 'Cloud Determination Code_statistically derived', 'Visibiliy Quality Code_p', 'Visibility Variability Code_variable', 'Temperature Quality Code_suspect, data originate from an ncei data source']\n"
     ]
    }
   ],
   "source": [
    "X_dtype = X_train_encoded.select_dtypes(include=['bool']).reset_index(drop=True)\n",
    "\n",
    "var_thr = VarianceThreshold(threshold=0.001)  # Removing both constant and quasi-constant\n",
    "var_thr.fit(X_dtype)\n",
    "\n",
    "concol = [column for column in X_dtype.columns\n",
    "          if column not in X_dtype.columns[var_thr.get_support()]]\n",
    "\n",
    "\n",
    "del var_thr, X_dtype\n",
    "\n",
    "if \"Weather Type\" in concol:\n",
    "    concol.remove(\"Weather Type\")\n",
    "\n",
    "print(f\"DROPPING BOOL: \", concol)\n",
    "X_train_encoded.drop(concol, axis=1, inplace=True)\n",
    "X_test_encoded.drop(concol, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "X_dtype_train = X_train_encoded.select_dtypes(include=[np.number]).reset_index(drop=True)\n",
    "num_cols = list(X_dtype_train.columns)\n",
    "\n",
    "X_dtype_test = X_test_encoded.select_dtypes(include=[np.number]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_norm = min_max_scaler.fit_transform(X_dtype_train)\n",
    "X_test_norm = min_max_scaler.transform(X_dtype_test)\n",
    "\n",
    "X_train_encoded[num_cols] = X_train_norm\n",
    "X_test_encoded[num_cols] = X_test_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train_norm, X_test_norm, X_dtype_train, X_dtype_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linRidge = RidgeCV(alphas=[1e-3,1e-1, 1]).fit(X_train_encoded, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Disney dataset')\n",
    "print('ridge regression linear model intercept: {}'\n",
    "     .format(linRidge.intercept_))\n",
    "print('R-squared score (training): {:.3f}'\n",
    "     .format(linRidge.score(X_train_encoded, y_train)))\n",
    "print('R-squared score (test): {:.3f}'\n",
    "     .format(linRidge.score(X_test_encoded, y_test)))\n",
    "print('Number of non-zero features: {}'\n",
    "     .format(np.sum(linRidge.coef_ != 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X_train_encoded, X_test_encoded])\n",
    "y = pd.concat([y_train, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linRidge = RidgeCV(alphas=[1e-3,1e-1, 1]).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# force scores to be positive\n",
    "scores = absolute(scores)\n",
    "print('Mean MAE: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-11.m94",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-11:m94"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
