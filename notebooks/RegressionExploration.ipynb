{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import importlib.util\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parse_times = [\"MKOPEN\", \"MKCLOSE\", \"MKEMHOPEN\", \"MKEMHCLOSE\",\n",
    "               \"MKOPENYEST\", \"MKCLOSEYEST\", \"MKOPENTOM\",\n",
    "               \"MKCLOSETOM\",\"EPOPEN\", \"EPCLOSE\", \"EPEMHOPEN\",\n",
    "               \"EPEMHCLOSE\", \"EPOPENYEST\", \"EPCLOSEYEST\",\n",
    "               \"EPOPENTOM\", \"EPCLOSETOM\", \"HSOPEN\", \"HSCLOSE\",\n",
    "               \"HSEMHOPEN\", \"HSEMHCLOSE\", \"HSOPENYEST\", \"HSCLOSEYEST\",\n",
    "               \"HSOPENTOM\", \"HSCLOSETOM\", \"AKOPEN\", \"AKCLOSE\",\n",
    "               \"AKEMHOPEN\", \"AKOPENYEST\", \"AKCLOSEYEST\",\"AKEMHCLOSE\",\n",
    "               \"AKOPENTOM\", \"AKCLOSETOM\", \"MKPRDDT1\", \"MKPRDDT2\",\n",
    "               \"MKPRDNT1\", \"MKPRDNT2\", \"MKFIRET1\", \"MKFIRET2\",\n",
    "               \"EPFIRET1\", \"EPFIRET2\", \"HSPRDDT1\", \"HSFIRET1\",\n",
    "               \"HSFIRET2\", \"HSSHWNT1\", \"HSSHWNT2\", \"AKPRDDT1\",\n",
    "               \"AKPRDDT2\", \"AKSHWNT1\", \"AKSHWNT2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load posted wait time datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the module that needs to be\n",
    "# imported relative to the path of the\n",
    "# module\n",
    "spec = importlib.util.spec_from_file_location(\"loadTrainTestPostedWaitTimes\", \"../src/data/loadTrainTestData.py\")\n",
    "\n",
    "# creates a new module based on spec\n",
    "loadTrainPosted = importlib.util.module_from_spec(spec)\n",
    "\n",
    "# executes the module in its own namespace\n",
    "# when a module is imported or reloaded.\n",
    "spec.loader.exec_module(loadTrainPosted)\n",
    "\n",
    "X_train, X_test, y_train, y_test = loadTrainPosted.loadTrainTestPostedWaitTimes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert key data points from date to integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"MONTHOFYEAR\"] = X_train[\"date\"].dt.month.astype(\"Int8\")\n",
    "X_train[\"YEAR\"] = X_train[\"date\"].dt.year.astype(\"Int16\")\n",
    "X_train[\"DAYOFYEAR\"] = X_train[\"date\"].dt.dayofyear.astype(\"Int16\")\n",
    "X_train[\"HOUROFDAY\"] = X_train[\"datetime\"].dt.hour.astype(\"Int8\")\n",
    "\n",
    "X_test[\"MONTHOFYEAR\"] = X_test[\"date\"].dt.month.astype(\"Int8\")\n",
    "X_test[\"YEAR\"] = X_test[\"date\"].dt.year.astype(\"Int16\")\n",
    "X_test[\"DAYOFYEAR\"] = X_test[\"date\"].dt.dayofyear.astype(\"Int16\")\n",
    "X_test[\"HOUROFDAY\"] = X_test[\"datetime\"].dt.hour.astype(\"Int8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort by datetime before imputation (keeping y-values associated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([X_train, y_train], axis=1).sort_values(['datetime'])\n",
    "test = pd.concat([X_test, y_test], axis=1).sort_values(['datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_impute = train.drop(columns=[\"POSTED_WAIT\"])\n",
    "y_train = train[\"POSTED_WAIT\"]\n",
    "\n",
    "X_test_impute = test.drop(columns=[\"POSTED_WAIT\"])\n",
    "y_test = test[\"POSTED_WAIT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Many open/close times, parade times, etc. are in HH:MM format. \n",
    "\n",
    "Convert to integer hour & fill nulls with 99.\n",
    "\n",
    "This means that particulate event does not exist for that day. (e.g. Magic Kingdom doesn't have a second parade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in parse_times:\n",
    "    X_train_impute[col] =  X_train_impute[col].fillna(\"99\")\n",
    "    X_train_impute[f\"{col}_HOUR\"] = X_train_impute[col].apply(lambda x: x[:2] if x[0]!=0 else x[:1]).astype(int).astype(\"Int8\")\n",
    "    X_train_impute.drop(columns = col, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in parse_times:\n",
    "    X_test_impute[col] =  X_test_impute[col].fillna(\"99\")\n",
    "    X_test_impute[f\"{col}_HOUR\"] = X_test_impute[col].apply(lambda x: x[:2] if x[0]!=0 else x[:1]).astype(int).astype(\"Int8\")\n",
    "    X_test_impute.drop(columns = col, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in X_train_impute.columns:\n",
    "    nulls = X_train_impute[col].isnull().sum()\n",
    "    \n",
    "    if nulls>0:\n",
    "        print(col)\n",
    "        X_train_impute[col].fillna(method ='bfill', inplace=True)\n",
    "    \n",
    "        if X_train_impute[col].isnull().sum()>0:\n",
    "            X_train_impute[col].fillna(X_train_impute[col].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in X_test_impute.columns:\n",
    "    nulls = X_test_impute[col].isnull().sum()\n",
    "    \n",
    "    if nulls>0:\n",
    "        print(col)\n",
    "        X_test_impute[col]= X_test_impute[col].fillna(method ='bfill')\n",
    "        \n",
    "        if X_test_impute[col].isnull().sum()>0:\n",
    "            X_test_impute[col].fillna(X_test_impute[col].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_encoded = X_train_impute.drop(columns=['date', 'datetime', 'Unnamed: 0'])\n",
    "X_test_encoded = X_test_impute.drop(columns=['date', 'datetime', 'Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train_impute, X_test_impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dtype = X_train_encoded.select_dtypes(include=['bool']).reset_index(drop=True)\n",
    "\n",
    "var_thr = VarianceThreshold(threshold=0.001)  # Removing both constant and quasi-constant\n",
    "var_thr.fit(X_dtype)\n",
    "\n",
    "concol = [column for column in X_dtype.columns\n",
    "          if column not in X_dtype.columns[var_thr.get_support()]]\n",
    "\n",
    "\n",
    "del var_thr, X_dtype\n",
    "\n",
    "if \"Weather Type\" in concol:\n",
    "    concol.remove(\"Weather Type\")\n",
    "\n",
    "print(f\"DROPPING BOOL: \", concol)\n",
    "X_train_encoded.drop(concol, axis=1, inplace=True)\n",
    "X_test_encoded.drop(concol, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "X_dtype_train = X_train_encoded.select_dtypes(include=[np.number]).reset_index(drop=True)\n",
    "num_cols = list(X_dtype_train.columns)\n",
    "\n",
    "X_dtype_test = X_test_encoded.select_dtypes(include=[np.number]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_norm = scaler.fit_transform(X_dtype_train)\n",
    "X_test_norm = scaler.transform(X_dtype_test)\n",
    "\n",
    "X_train_encoded[num_cols] = X_train_norm\n",
    "X_test_encoded[num_cols] = X_test_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train_norm, X_test_norm, X_dtype_train, X_dtype_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummy Regression - Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_dummy_mean = DummyRegressor(strategy = 'mean').fit(X_train_encoded, y_train)\n",
    "y_predict_dummy_mean = lm_dummy_mean.predict(X_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean squared error (dummy): {:.2f}\".format(metrics.mean_squared_error(y_test, \n",
    "                                                                     y_predict_dummy_mean)))\n",
    "\n",
    "print('Mean Absolute Error (MAE):', metrics.mean_absolute_error(y_test, y_predict_dummy_mean))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_dummy_median = DummyRegressor(strategy = 'median').fit(X_train_encoded, y_train)\n",
    "y_predict_dummy_median = lm_dummy_median.predict(X_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean squared error (dummy): {:.2f}\".format(metrics.mean_squared_error(y_test, \n",
    "                                                                     y_predict_dummy_median)))\n",
    "\n",
    "print('Mean Absolute Error (MAE):', metrics.mean_absolute_error(y_test, y_predict_dummy_median))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression Grid Search on Alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linRidge = RidgeCV(alphas=[1e-1, 1, 10], scoring='neg_mean_absolute_error').fit(X_train_encoded, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disney dataset\n",
      "ridge regression linear model intercept: -186.69367854762902\n",
      "R-squared score (training): 0.173\n",
      "R-squared score (test): 0.173\n",
      "Number of non-zero features: 376\n"
     ]
    }
   ],
   "source": [
    "print('Disney dataset')\n",
    "print('ridge regression linear model intercept: {}'\n",
    "     .format(linRidge.intercept_))\n",
    "print('R-squared score (training): {:.3f}'\n",
    "     .format(linRidge.score(X_train_encoded, y_train)))\n",
    "print('R-squared score (test): {:.3f}'\n",
    "     .format(linRidge.score(X_test_encoded, y_test)))\n",
    "print('Number of non-zero features: {}'\n",
    "     .format(np.sum(linRidge.coef_ != 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "del linRidge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(n_estimators=10, random_state=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create regressor object\n",
    "regressor = RandomForestRegressor(n_estimators = 10, random_state = 0)\n",
    " \n",
    "# fit the regressor with x and y data\n",
    "regressor.fit(X_train_encoded, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = regressor.predict(X_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 32.55780451043366\n",
      "Mean Squared Error (MSE): 14946.978712447142\n",
      "Root Mean Squared Error (RMSE): 122.25783701852059\n",
      "Mean Absolute Percentage Error (MAPE): inf\n",
      "Accuracy: -inf\n"
     ]
    }
   ],
   "source": [
    "print('Mean Absolute Error (MAE):', metrics.mean_absolute_error(y_test, pred))\n",
    "print('Mean Squared Error (MSE):', metrics.mean_squared_error(y_test, pred))\n",
    "print('Root Mean Squared Error (RMSE):', np.sqrt(metrics.mean_squared_error(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = regressor.feature_importances_\n",
    "#\n",
    "# Sort the feature importance in descending order\n",
    "#\n",
    "sorted_indices = np.argsort(importances)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['HOUROFDAY', 'Age_of_ride_years',\n",
       "       'Ride_name_walt disney's carousel of progress', 'Age_of_ride_days',\n",
       "       'Ride_duration_min', 'CapacityLostWGT_MK', 'MKEMHCLOSE_HOUR',\n",
       "       'Temperature (C)', 'MKOPEN_HOUR', 'Wind Angle', 'TL_rank', 'Wind Speed',\n",
       "       'WDW_TICKET_SEASON_none', 'Ride_name_prince charming regal carrousel',\n",
       "       'Cloud Height', 'CapacityLost_MK', 'WDWMINTEMP', 'WDWMAXTEMP',\n",
       "       'WDWMEANTEMP', 'WEATHER_WDWLOW', 'Park_area_fantasyland',\n",
       "       'Ride_name_tomorrowland transit authority peoplemover', 'DAYOFYEAR',\n",
       "       'HOLIDAYPX', 'MKEMHMORN', 'MKeventN_dah', 'DAYOFWEEK', 'MKCLOSE_HOUR',\n",
       "       'MKFIREN_happily ever after', 'MKFIREN_happy hallowishes fireworks',\n",
       "       'WEATHER_WDWHIGH', 'CapacityLost_EP', 'Visibility Distance (M)',\n",
       "       'MKHOURSEMH', 'Ride_name_jungle cruise', 'MKEMHOPEN_HOUR',\n",
       "       'Park_area_tomorrowland', 'MKHOURSEMHYEST', 'Height_req_inches',\n",
       "       'Ride_type_dark', 'MKHOURSEMHTOM', 'MKFIRET1_HOUR', 'new_case',\n",
       "       'MKHOURS', 'inSession', 'CapacityLostWGT_EP',\n",
       "       'Cloud Quality Code_passed all quality control checks, data originate from an ncei data source',\n",
       "       'TA_Stars', 'HSHOURSEMHTOM', 'inSession_DC'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_encoded.columns[sorted_indices[:50]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-11.m94",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-11:m94"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
